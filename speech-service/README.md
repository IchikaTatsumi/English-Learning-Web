Speech Service - Python Backend
Speech Recognition (STT) vÃ  Text-to-Speech (TTS) service sá»­ dá»¥ng Vosk vÃ  gTTS.
ğŸ“‹ Prerequisites

Python 3.8+
ffmpeg (cho audio processing)
Vosk model (download riÃªng)

ğŸš€ Setup
1. Táº¡o Virtual Environment
``
cd speech
python -m venv venv

``
# Activate
# Linux/Mac:
source venv/bin/activate
# Windows:
venv\Scripts\activate
2. Install Dependencies
``
pip install -r requirements.txt
``

3. Install ffmpeg
Ubuntu/Debian:
``
sudo apt-get update
sudo apt-get install ffmpeg
``
MacOS:
``
MacOS:
``
Windows:
Download tá»« https://ffmpeg.org/download.html vÃ  thÃªm vÃ o PATH
4. Download Vosk Model
``
# Download model (370MB)
wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip

# Extract
unzip vosk-model-small-en-us-0.15.zip -d speech-recognition/models/

# Hoáº·c download manually vÃ  extract vÃ o thÆ° má»¥c:
# speech-recognition/models/vosk-model-small-en-us-0.15/
``
5. Configure Environment
``
cp .env.example .env
# Edit .env náº¿u cáº§n thay Ä‘á»•i cáº¥u hÃ¬nh
``
6. Create Required Directories
``
mkdir -p speech-synthesis/voices
mkdir -p speech-recognition/models
``
ğŸƒ Run Server
# Development
``
python main.py
``
# Hoáº·c vá»›i uvicorn:
``
uvicorn main:app --host 0.0.0.0 --port 5000 --reload
``
# Production
``
uvicorn main:app --host 0.0.0.0 --port 5000 --workers 4
``
ğŸ“¡ API Endpoints
# Health Check
``
GET /health
``
# Speech to Text (STT)
``
POST /api/speech/recognize
Content-Type: multipart/form-data

file: audio.wav
``
Response:
{
  "recognized_text": "hello world",
  "confidence": 0.95,
  "success": true
}
# Text to Speech (TTS)
POST /api/speech/synthesize
Content-Type: application/json

{
  "text": "Hello world",
  "lang": "en",
  "slow": false
}
Response:
json{
  "audio_url": "/api/speech/audio/tts_abc123.mp3",
  "duration": 2.5,
  "success": true
}
Simple TTS (Quick Test)
bashGET /api/speech/tts-simple?text=Hello

ğŸ³ Docker Deployment
# Build Image
``
docker build -t speech-service .
``
# Docker compose
yaml
``
services:
  speech-service:
    build: ./speech
    ports:
      - "5000:5000"
    environment:
      - PORT=5000
      - VOSK_MODEL_PATH=/app/models/vosk-model-small-en-us-0.15
    volumes:
      - ./speech/speech-synthesis/voices:/app/speech-synthesis/voices

``
ğŸ“ Project Structure
speech/
â”œâ”€â”€ main.py                          # FastAPI app
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ README.md
â”œâ”€â”€ speech-recognition/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vosk_service.py             # Vosk STT service
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ vosk-model-small-en-us-0.15/
â””â”€â”€ speech-synthesis/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ tts_service.py              # gTTS service
    â””â”€â”€ voices/                      # Generated audio files
âš™ï¸ Configuration
Environment variables trong .env:

PORT: Server port (default: 5000)
VOSK_MODEL_PATH: Path to Vosk model
AUDIO_OUTPUT_DIR: Directory for generated audio
TTS_CACHE_ENABLED: Enable/disable audio caching
LOG_LEVEL: Logging level (INFO, DEBUG, ERROR)

ğŸ”§ Troubleshooting
"Model not found" error

Äáº£m báº£o Ä‘Ã£ download vÃ  extract Vosk model Ä‘Ãºng vá»‹ trÃ­
Check VOSK_MODEL_PATH trong .env

"ffmpeg not found" error

Install ffmpeg theo hÆ°á»›ng dáº«n á»Ÿ trÃªn
Verify: ffmpeg -version

"Audio format not supported"

Äáº£m báº£o audio file lÃ  WAV, MP3, hoáº·c WebM
Server sáº½ tá»± Ä‘á»™ng convert sang Ä‘á»‹nh dáº¡ng phÃ¹ há»£p

Port already in use

Thay Ä‘á»•i PORT trong .env
Hoáº·c kill process Ä‘ang dÃ¹ng port: lsof -ti:5000 | xargs kill

ğŸ“ Notes

Vosk model "small-en-us" (370MB) phÃ¹ há»£p cho development
Vá»›i production, xem xÃ©t dÃ¹ng model lá»›n hÆ¡n Ä‘á»ƒ accuracy tá»‘t hÆ¡n
TTS caching giÃºp giáº£m thá»i gian response cho text Ä‘Ã£ generate
Audio files sáº½ Ä‘Æ°á»£c cleanup tá»± Ä‘á»™ng sau 24h (cÃ³ thá»ƒ config)


ğŸ”— Integration vá»›i NestJS Backend
Trong NestJS backend, gá»i Python service qua HTTP:

``
// speech.adapter.ts
async recognizeSpeech(audioData: string) {
  const formData = new FormData();
  formData.append('file', audioData);
  
  const response = await axios.post(
    'http://localhost:5000/api/speech/recognize',
    formData
  );
  
  return response.data;
}
``
